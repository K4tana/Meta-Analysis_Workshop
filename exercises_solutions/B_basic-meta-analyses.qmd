---
title: "B: Basic meta-analyses"
format: html
editor_options: 
  chunk_output_type: console
---

```{r}
library(tidyverse)
library(metafor)
```

# Exercise B

Use the `metadat::dat.normand1999` dataset in metafor. 
This dataset contains results from 9 studies on length of 
hospital stay in days for stroke patients who receive
either specialized care or routine care.
See `?metadat::dat.normand1999` for details.
      
1. Make a new dataset with **standardized mean differences**, but compute the
   sampling error variance for studies by using the **average effect size** 
   across the included studies by adding the argument `vtype = "AV"` to your 
   `escalc()` call. 
   
```{r}
dat_g <- escalc(
  measure = "SMD",
  vtype = "AV",
  data = dat.normand1999,
  m1i = m1i, sd1i = sd1i, n1i = n1i,
  m2i = m2i, sd2i = sd2i, n2i = n2i
)
```

   A. Make a forest plot of these data. Include study labels.

```{r}
with(dat_g, forest(yi, vi = vi, slab = source))
```
   
   B. Fit random-effects, fixed-effects, and equal-effects meta-analyses 
      using these data. Interpret the results for each model appropriately.

```{r}
mod_ee <- rma(yi = yi ~ 1, vi = vi, data = dat_g, method = "EE", slab = source, test = "t")

mod_fe <- rma(yi = yi ~ 1, vi = vi, data = dat_g, method = "FE", slab = source, test = "t")

mod_re <- rma(yi = yi ~ 1, vi = vi, data = dat_g, method = "REML", slab = source, test = "knha")
```
   
```{r}
mod_ee
```

  - The equal effects model assumes that there is no true variability. 
    The Q test has *p* < .0001, indicating that this model fits the model very
    poorly and should be rejected.

```{r}
mod_fe
```

  - The fixed effects model summarizes the mean effect *in this sample*.
    It does *not* assume that there is no true variability. 
    The average effect in this sample is *g* = -0.4106 [95% CI -.55, -.27],
    indicating a moderate size effect by conventional standards.
    The Q test has *p* < .0001, indicating that these effects are heterogeneous.
    
```{r}
mod_re

confint(mod_re)
```

  - The random effects model estimates the mean and standard deviation of 
    effects in a population represented by the sample studies. 
    The average effect in the population is estimated to be *g* = -0.54 [95% CI -1.25, .18],
    indicating a moderate to large mean effect by conventional standards, though
    the uncertainty interval ranges from very strongly beneficial to somewhat harmful.
    The Q test has *p* < .0001, strongly indicating that these effects are heterogeneous.
    The estimated random effects SD is .89 [95% .57, 1.76], indicating a very
    large amount of heterogeneity. More studies are needed to understand the
    effect of this treatment.

   C. Make a forest plot of your random-effects model results.
      Include study labels and a prediction interval on this plot.
      
```{r}
forest(mod_re, addpred = TRUE)
```

      
2. Make a dataset with **raw mean differences** (`measure = "MD"`).

```{r}
dat_md <- escalc(
  measure = "MD",
  vtype = "UB",
  data = dat.normand1999,
  m1i = m1i, sd1i = sd1i, n1i = n1i,
  m2i = m2i, sd2i = sd2i, n2i = n2i
)
```

   A. Fit a random-effects meta-analysis using these data and interpret 
      the results.
      
```{r}
mod_md <- rma(yi = yi ~ 1, vi = vi, data = dat_md, method = "REML", slab = source, test = "knha")

mod_md
confint(mod_md)
```

  - The average treatment effect in the population is estimated to be 
    a reduction of -15.11 [95% CI -36.32, 6.11] days in hospital for patients
    receiving specialized care compared to routine care. The uncertainty interval 
    ranges from -36 days shorter to 6 days *longer*.
    The Q test has *p* < .0001, strongly indicating that these effects are heterogeneous.
    The estimated random effects SD is 26.16 days [95% 17.11, 53.75], 
    indicating a very large amount of heterogeneity. More studies are needed to 
    understand the effect of this treatment.
    
   B. What are benefits and limitations of using raw versus standardized effect
      sizes in research?
      
   - Raw effect sizes are often more interpretable than standardized effects.
     Standardized effects may be easier to use if studies vary in the measures
     they use for each variable. Standardized effects may also be more
     interpretable if the raw variable scales are relatively arbitrary.
      

Use the `metadat::dat.crede2010` dataset in metafor. 
This dataset contains results from 97 studies on the 
association between study time and college course performance.
See `?metadat::dat.crede2010` for details.

3. Make a dataset with **unbiased correlations** as the effect size.
   Use the average effect size to compute sampling error variances.
   Include only rows where `criterion` is equal to `"grade"`.
   
```{r}
dat_ucor <- escalc(
  measure = "UCOR",
  vtype = "AV",
  data = filter(dat.crede2010, criterion == "grade"),
  ni = ni,
  ri = ri
)
```

   A. Fit a random effects model to these data and interpret the results.

```{r}
mod_ucor <- rma(yi = yi ~ 1, vi = vi, data = dat_ucor, method = "REML", test = "knha")

mod_ucor
confint(mod_ucor)
```

  - The average correlation between study time and course grades is
    *r* = .41 [95% CI .36, .45], indicating a large mean effect by conventional
    standards. The uncertainty interval includes consistently large correlations,
    so we are confident this relationship is large on average.
    The Q test has *p* < .0001, strongly indicating that these effects are heterogeneous.
    The estimated random effects SD is .15 [95% .23, .19], indicating a 
    moderate amount of heterogeneity.
   
   B. Compute a confidence interval for the mean and a prediction interval
      for individual study effects. Interpret these.
      
```{r}
predict(mod_ucor)
```

  - The confidence interval for the mean ranges from .36 to .45. This indicates
    uncertainty in the *average* correlation, the range where we expect the true
    mean effect to be.
  - The prediction interval for individual studies ranges from .10 to .71. This
    indicates the range where we expect true individual study effects to fall.
    This indicates that although we are confident the average relationship
    between study time and grades is large, we still expect some settings
    (i.e., studies) where the relationship is weak (and some where it is 
    extremely strong).
    

4. Make a dataset with **z-transformed correlations** as the effect size.
   Include only rows where `criterion` is equal to `"grade"`.
   
```{r}
dat_zcor <- escalc(
  measure = "ZCOR",
  data = filter(dat.crede2010, criterion == "grade"),
  ni = ni,
  ri = ri
)
```
   
   A. Fit a random effects model to these data.
      Compute a confidence interval for the mean and a prediction interval
      for individual studies for **correlations** by back-transforming.
      
```{r}
mod_zcor <- rma(yi = yi ~ 1, vi = vi, data = dat_zcor, method = "REML", test = "knha")

# best back-transformation
predict(mod_zcor, transf = transf.ztor.int, targs = list(tau2 = mod_zcor$tau2, lower = -4, upper = 4))

# most common back-transformation
# -- strictly speaking, this gives the estimated *median* correlation (not mean)
predict(mod_zcor, transf = transf.ztor)
```
      